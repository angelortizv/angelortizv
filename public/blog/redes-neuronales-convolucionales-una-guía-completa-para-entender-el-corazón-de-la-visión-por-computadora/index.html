<html>

<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <link rel="icon" href="//localhost:1313/images/letter-a.png">
    
    <link rel="stylesheet" href="//localhost:1313/scss/global.min.7f9dc5967916e9e0ab39b5feb71932f3865d2c616ba3d8ce018452ed8886ead1.css">
    
    <link rel="stylesheet" href="//localhost:1313/css/prism.css" />
    <link href="https://fonts.googleapis.com/css?family=Merriweather&display=swap" rel="stylesheet">
    

 





	




<title>Redes Neuronales Convolucionales: Una Guía Completa para Entender el Corazón de la Visión por Computadora | angelortizv </title>
<meta name="description" content="Las Redes Neuronales Convolucionales, también conocidas como ConvNets o CNNs, son modelos de aprendizaje profundo que han revolucionado el campo de la visión por computadora. Estos algoritmos son la base para el reconocimiento de objetos, incluyendo la clasificación, detección y segmentación de imágenes. Se distinguen por su capacidad para procesar datos con una topología de cuadrícula, como las imágenes.
En este artículo, exploraremos qué son las RNC, sus componentes fundamentales, cómo funcionan y las arquitecturas históricas que impulsaron su éxito.">
<meta property="og:title" content="Redes Neuronales Convolucionales: Una Guía Completa para Entender el Corazón de la Visión por Computadora | angelortizv ">
<meta property="og:site_name" content="angelortizv ">
<meta property="og:description" content="Las Redes Neuronales Convolucionales, también conocidas como ConvNets o CNNs, son modelos de aprendizaje profundo que han revolucionado el campo de la visión por computadora. Estos algoritmos son la base para el reconocimiento de objetos, incluyendo la clasificación, detección y segmentación de imágenes. Se distinguen por su capacidad para procesar datos con una topología de cuadrícula, como las imágenes.
En este artículo, exploraremos qué son las RNC, sus componentes fundamentales, cómo funcionan y las arquitecturas históricas que impulsaron su éxito.">
<meta property="og:url" content="//localhost:1313/blog/redes-neuronales-convolucionales-una-gu%C3%ADa-completa-para-entender-el-coraz%C3%B3n-de-la-visi%C3%B3n-por-computadora/">
<meta property="og:type" content="website">
<meta property="og:locale" content="en_US">
<meta property="og:image" content='//localhost:1313/uploads/content/2025/2025-cnn.png'><meta name="twitter:card" content="">
<meta name="twitter:title" content="Redes Neuronales Convolucionales: Una Guía Completa para Entender el Corazón de la Visión por Computadora | angelortizv ">

	<link rel="canonical" href="//localhost:1313/blog/redes-neuronales-convolucionales-una-gu%C3%ADa-completa-para-entender-el-coraz%C3%B3n-de-la-visi%C3%B3n-por-computadora/">


	<meta name="twitter:description" content="Las Redes Neuronales Convolucionales, también conocidas como ConvNets o CNNs, son modelos de aprendizaje profundo que han revolucionado el campo de la visión por computadora. Estos algoritmos son la base para el reconocimiento de objetos, incluyendo la clasificación, detección y segmentación de imágenes. Se distinguen por su capacidad para procesar datos con una topología de cuadrícula, como las imágenes.
En este artículo, exploraremos qué son las RNC, sus componentes fundamentales, cómo funcionan y las arquitecturas históricas que impulsaron su éxito.">
<meta name="twitter:image" content="//localhost:1313/uploads/content/2025/2025-cnn.png">
<meta property="article:published_time" content="2025-10-10T17:42:00-06:00">
	<meta property="article:updated_time" content="2025-10-10T17:42:00-06:00">



    </head>


<body class="line-numbers">

    
    <script src="//localhost:1313/js/initColors.js"></script>

    <div class="layout-styled">

        <Section class="section">
    <div class="nav-container">
      <a class="logo-link" href="//localhost:1313/">
        <div id="logo-desktop">
        <svg
        width="265"
        height="50"
        viewBox="0 0 192 23"
        className="Logo__Desktop"

        version="1.1" 
        viewBox="0 0 77.428 32.953" 
        xmlns="http://www.w3.org/2000/svg" 
        xmlns:cc="http://creativecommons.org/ns#" 
        xmlns:dc="http://purl.org/dc/elements/1.1/" 
        xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns">
        
        <g transform="translate(+10 -72.399)">
            <text class="change-fill"  x="-0.76714724" y="98.489014" fill="#000000" font-size="37.922px" letter-spacing="0px" stroke-width=".94805" word-spacing="0px" style="line-height:1.25" xml:space="preserve"><tspan x="-0.76714724" y="98.489014" font-family="'Ubuntu Mono'" stroke-width=".94805">angelortizv</tspan></text>
        </g>
      </svg>
</div>


<div id="logo-mobile" class="hidden">
    <svg version="1.0" xmlns="http://www.w3.org/2000/svg"
    width="10" height="10" viewBox="0 0 512.000000 512.000000"
    >


   </svg>
</div>
        <span class="header-hidden">Navigate back to the homepage</span>
      </a>
      <div class="nav-controls">
        <button id="copyButton" class="icon-wrapper">
          <svg
    class="icon-image"
    width="24"
    height="20"
    viewBox="0 0 24 20"
    fill="none"
    xmlns="http://www.w3.org/2000/svg"
    >
    <path
      fillRule="evenodd"
      clipRule="evenodd"
      d="M2 5C2 3.34328 3.34328 2 5 2H14C15.6567 2 17 3.34328 17 5V9C17 10.6567 15.6567 12 14 12H10C9.44771 12 9 12.4477 9 13C9 13.5523 9.44771 14 10 14H14C16.7613 14 19 11.7613 19 9V5C19 2.23872 16.7613 0 14 0H5C2.23872 0 0 2.23872 0 5V9C0 10.4938 0.656313 11.8361 1.6935 12.7509C2.10768 13.1163 2.73961 13.0767 3.10494 12.6625C3.47028 12.2483 3.43068 11.6164 3.0165 11.2511C2.39169 10.6999 2 9.89621 2 9V5ZM7 11C7 9.34328 8.34328 8 10 8H14C14.5523 8 15 7.55228 15 7C15 6.44772 14.5523 6 14 6H10C7.23872 6 5 8.23872 5 11V15C5 17.7613 7.23872 20 10 20H19C21.7613 20 24 17.7613 24 15V11C24 9.50621 23.3437 8.16393 22.3065 7.24906C21.8923 6.88372 21.2604 6.92332 20.8951 7.3375C20.5297 7.75168 20.5693 8.38361 20.9835 8.74894C21.6083 9.30007 22 10.1038 22 11V15C22 16.6567 20.6567 18 19 18H10C8.34328 18 7 16.6567 7 15V11Z"
      fill="#000"
    />
</svg>
          <div id="toolTip" class="tool-tip " >
              copied
          </div>
          <input id="copyText" style="opacity: 0;" type="text" class="tool-tip " />
        </button>
  
        <button id="themeColorButton" class="icon-wrapper"> 
          <div id="sunRays" class="sun-rays"></div>
          <div id="moonOrSun" class="moon-or-sun"></div>
          <div id="moonMask" class="moon-mask"></div>
        </button>
      </div>
  </div>
  </Section>
  
  
  <script src="//localhost:1313/js/toggleLogos.js"></script>
  
  
  <script src="//localhost:1313/js/toggleColors.js"></script>
  
  
  <script src="//localhost:1313/js/copyUrl.js"></script>

        

<section class="section narrow">

    <section id="articleHero" class="section narrow">
    <div class="article-hero">
        <header class="article-header">
            <h1 class="article-hero-heading">Redes Neuronales Convolucionales: Una Guía Completa para Entender el Corazón de la Visión por Computadora</h1>
            <div class="article-hero-subtitle">
                <div class="article-meta">
                    


    
            <a href="//localhost:1313/authors/angelo-ortiz-vega/" class="article-author-link">
                
                    <div class="article-author-avatar">
                        <img src="//localhost:1313/uploads/angelortizv.jpeg" />
                    </div>
                
                
                <strong>Angelo Ortiz Vega</strong>
                
                <span class="hide-on-mobile">,&nbsp;</span>
            </a>
    



<script src="//localhost:1313/js/collapseAuthors.js"></script>
                    October 10, 2025
                    • 10 min read
                </div>
            </div>
        </header>
        
        <div class="article-hero-image" id="ArticleImage__Hero">
            <img src="//localhost:1313/uploads/content/2025/2025-cnn.png">
        </div>
        
    </div>
</section>


    <aside id="progressBar" class="aside-container">
    <div class="aside-align">
      <div>
        <div class="overlap-container">
        </div>
      </div>
    </div>

    <div class="progress-container" tabIndex={-1}>
        <div class="track-line" aria-hidden="true">
            <div id="progressIndicator" class="progress-line"></div>
        </div>
    </div>
</aside>


    <article  id="articleContent" class="post-content" style="position:relative;">
        <p>Las Redes Neuronales Convolucionales, también conocidas como ConvNets o CNNs, son modelos de aprendizaje profundo que han revolucionado el campo de la visión por computadora. Estos algoritmos son la base para el reconocimiento de objetos, incluyendo la clasificación, detección y segmentación de imágenes. Se distinguen por su capacidad para procesar datos con una topología de cuadrícula, como las imágenes.</p>
<p>En este artículo, exploraremos qué son las RNC, sus componentes fundamentales, cómo funcionan y las arquitecturas históricas que impulsaron su éxito.</p>
<h2 id="1-qué-es-una-rnc-y-por-qué-es-importante">1. ¿Qué es una RNC y Por Qué es Importante?</h2>
<p>Una RNC es un tipo especializado de algoritmo de <em>deep learning</em> (aprendizaje profundo). A diferencia de las redes neuronales regulares, que transforman la entrada en un vector, las RNC operan con volúmenes 3D de neuronas: <strong>ancho, alto y profundidad</strong>.</p>
<h3 id="inspiración-y-principios-clave">Inspiración y Principios Clave</h3>
<p>Las RNC se inspiraron en la arquitectura de la <strong>corteza visual humana</strong>, compartiendo varias similitudes:</p>
<ul>
<li><strong>Arquitectura Jerárquica:</strong> Ambas estructuras extraen características simples en las capas iniciales y construyen representaciones más sofisticadas en las capas más profundas.</li>
<li><strong>Conectividad Local:</strong> Las neuronas se conectan solo a una región local de la entrada (no al campo visual completo), lo que permite una mayor eficiencia.</li>
<li><strong>Invarianza de Traslación:</strong> Las RNC poseen características de invarianza de traslación, lo que les permite identificar patrones sin importar variaciones en la posición, orientación, escala o traslación de las características en los datos.</li>
</ul>
<h3 id="importancia-de-las-rnc">Importancia de las RNC</h3>
<p>Las RNC son cruciales en el mundo moderno por varias razones:</p>
<ol>
<li><strong>Extracción Autónoma de Características:</strong> Extraen características a gran escala de forma autónoma, superando a los algoritmos clásicos de <em>machine learning</em> como las SVM y los árboles de decisión, eliminando la necesidad de ingeniería manual de características.</li>
<li><strong>Versatilidad:</strong> Aunque son famosas por la clasificación de imágenes, las RNC también se aplican en otros dominios, incluyendo el procesamiento del lenguaje natural, el análisis de series de tiempo y el reconocimiento de voz.</li>
<li><strong>Modelos Preentrenados:</strong> Arquitecturas de alto rendimiento como VGG-16, ResNet50 e Inceptionv3 se pueden adaptar a nuevas tareas (mediante <em>fine-tuning</em>) con relativamente pocos datos.</li>
</ol>
<h2 id="2-componentes-clave-de-una-rnc">2. Componentes Clave de una RNC</h2>
<p>Las Redes Neuronales Convolucionales están construidas a partir de una secuencia de capas que transforman un volumen de entrada 3D en un volumen de salida 3D. Los componentes principales son:</p>
<h3 id="21-capas-convolucionales-conv">2.1. Capas Convolucionales (CONV)</h3>
<p>Esta es la capa central y el principal bloque de construcción, donde ocurre la mayor parte del trabajo computacional.</p>
<ul>
<li><strong>La Operación de Convolución:</strong> Implica la aplicación de un <strong>filtro</strong> (o <em>kernel</em>), que es una matriz de pesos, que se desliza (o convoluciona) sobre la matriz de píxeles de la imagen.</li>
<li><strong>Detección de Características:</strong> En esta capa, se aplican varios filtros, cada uno diseñado para reconocer un patrón específico del input, como líneas, curvas o bordes. El resultado de aplicar un filtro es un <strong>mapa de características</strong> (<em>feature map</em>).</li>
<li><strong>Pesos y Bias:</strong> Los pesos del <em>kernel</em> se determinan durante el proceso de entrenamiento. La operación en sí es un producto punto (multiplicación elemento por elemento y luego suma) entre el filtro y la región del input sobre la que se encuentra.</li>
<li><strong>Compartición de Parámetros:</strong> Una característica clave es que el mismo filtro se aplica en toda la imagen. Esto reduce drásticamente el número de parámetros, basándose en la suposición de que si una característica es útil en una posición, también lo será en otra (invarianza de traslación).</li>
</ul>
<h4 id="hiperparámetros-de-la-capa-conv">Hiperparámetros de la Capa CONV</h4>
<p>Tres hiperparámetros controlan el tamaño del volumen de salida:</p>
<ol>
<li><strong>Profundidad (Número de Filtros, $K$):</strong> Corresponde al número de filtros que se utilizan, y por lo tanto, a la profundidad del volumen de salida.</li>
<li><strong>Zancada (<em>Stride</em>, $S$):</strong> Es la distancia, en píxeles, que el <em>kernel</em> se mueve sobre la matriz de entrada. Un <em>stride</em> de 1 es común. La dimensión de la matriz convolucionada es inversamente proporcional al tamaño del <em>stride</em>.</li>
<li><strong>Relleno Cero (<em>Zero-Padding</em>, $P$):</strong> Consiste en rodear el volumen de entrada con ceros. Es útil para que los filtros encajen y, comúnmente, para asegurar que el tamaño espacial del volumen de salida sea igual al de la entrada (por ejemplo, $P = (F - 1) / 2$ si $S=1$ y $F$ es el tamaño del filtro).</li>
</ol>
<h3 id="22-función-de-activación-relu">2.2. Función de Activación (ReLU)</h3>
<p>Después de cada operación de convolución, se aplica una función de activación no lineal, siendo la más común la <strong>Unidad de Rectificación Lineal (ReLU)</strong>.</p>
<ul>
<li><strong>Propósito:</strong> Ayuda a la red a aprender relaciones no lineales entre las características de la imagen.</li>
<li><strong>Beneficio:</strong> Contribuye a mitigar el problema del gradiente desvanecedor (<em>vanishing gradient</em>).</li>
</ul>
<h3 id="23-capas-de-pooling">2.3. Capas de <em>Pooling</em></h3>
<p>Las capas de <em>Pooling</em> (agrupación o submuestreo) se insertan periódicamente entre las capas CONV. Su función es <strong>reducir progresivamente las dimensiones espaciales</strong> de la representación, lo que disminuye la complejidad computacional, la memoria utilizada y ayuda a controlar el sobreajuste.</p>
<ul>
<li><strong>Operación:</strong> La capa de <em>pooling</em> opera aplicando una función de agregación sobre el campo receptivo del filtro deslizante, pero este filtro no tiene pesos.</li>
<li><strong>Max Pooling:</strong> El tipo más común. Selecciona el valor máximo dentro de la región del mapa de características.</li>
<li><strong>Otros tipos:</strong> También existen el <em>Sum pooling</em> y el <em>Average pooling</em> (que fue común históricamente, pero <em>max pooling</em> ha demostrado ser más efectivo).</li>
<li><strong>Convención de Tamaño:</strong> Las configuraciones más comunes son un filtro de $2 \times 2$ con un <em>stride</em> de $S=2$, lo que reduce la entrada espacialmente en un 75%.</li>
</ul>
<h3 id="24-capas-totalmente-conectadas-fc">2.4. Capas Totalmente Conectadas (FC)</h3>
<p>Estas capas se encuentran al final de la RNC. La entrada de estas capas es el mapa de características unidimensional aplanado generado por la última capa de <em>pooling</em>.</p>
<ul>
<li><strong>Conexión Completa:</strong> Cada neurona en una capa FC está conectada a todas las activaciones de la capa anterior.</li>
<li><strong>Clasificación Final:</strong> La capa FC realiza la tarea de clasificación basándose en las características de alto nivel extraídas.</li>
<li><strong>Salida:</strong> Finalmente, una capa de predicción <strong>Softmax</strong> genera valores de probabilidad para cada etiqueta de salida posible, siendo la predicción final aquella con la puntuación de probabilidad más alta.</li>
</ul>
<h2 id="3-desafíos-y-técnicas-de-regularización">3. Desafíos y Técnicas de Regularización</h2>
<p>Un desafío común en las RNC es el <strong>sobreajuste</strong> (<em>overfitting</em>). Esto ocurre cuando el modelo aprende los datos de entrenamiento &ldquo;de memoria&rdquo;, incluyendo el ruido, lo que resulta en un buen rendimiento en los datos de entrenamiento, pero un mal rendimiento en datos nuevos o no vistos.</p>
<p>Dado que los modelos de <em>deep learning</em> como las RNC son propensos al sobreajuste debido a su alta complejidad, se utilizan varias estrategias de regularización para mitigarlo:</p>
<table>
  <thead>
      <tr>
          <th style="text-align: left">Técnica de Regularización</th>
          <th style="text-align: left">Descripción</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td style="text-align: left"><strong>Dropout</strong></td>
          <td style="text-align: left">Consiste en desactivar aleatoriamente algunas neuronas durante el entrenamiento, forzando a las neuronas restantes a aprender características robustas.</td>
      </tr>
      <tr>
          <td style="text-align: left"><strong>Normalización por Lotes</strong> (<em>Batch Normalization</em>)</td>
          <td style="text-align: left">Normaliza la capa de entrada ajustando y escalando las activaciones, lo que reduce el sobreajuste, acelera y estabiliza el proceso de entrenamiento.</td>
      </tr>
      <tr>
          <td style="text-align: left"><strong>Aumento de Datos</strong> (<em>Data Augmentation</em>)</td>
          <td style="text-align: left">Aumenta artificialmente el tamaño y la diversidad del conjunto de entrenamiento aplicando transformaciones aleatorias (rotación, escalado, volteo, recorte) a las imágenes.</td>
      </tr>
      <tr>
          <td style="text-align: left"><strong>Parada Temprana</strong> (<em>Early Stopping</em>)</td>
          <td style="text-align: left">Monitorea el rendimiento en los datos de validación y detiene el entrenamiento si el error de validación deja de mejorar.</td>
      </tr>
      <tr>
          <td style="text-align: left"><strong>Normalizaciones L1 y L2</strong></td>
          <td style="text-align: left">Añaden una penalización a la función de pérdida. L2 (<em>weight decay</em>) anima a que los pesos sean pequeños, evitando que tengan demasiada influencia en las predicciones.</td>
      </tr>
      <tr>
          <td style="text-align: left"><strong>Capas de <em>Pooling</em></strong></td>
          <td style="text-align: left">Reducen las dimensiones espaciales para proporcionar una forma abstracta de representación, disminuyendo la posibilidad de sobreajuste.</td>
      </tr>
  </tbody>
</table>
<h2 id="4-aplicaciones-prácticas-de-las-rnc">4. Aplicaciones Prácticas de las RNC</h2>
<p>Las RNC han transformado el campo de la visión por computadora y se aplican en escenarios prácticos como:</p>
<ul>
<li><strong>Clasificación de Imágenes:</strong> Asignar imágenes a categorías predefinidas (ej. organización automática de fotos en redes sociales).</li>
<li><strong>Detección de Objetos:</strong> Identificar y localizar múltiples objetos dentro de una imagen (ej. escaneo de estanterías en tiendas para identificar artículos agotados).</li>
<li><strong>Reconocimiento Facial:</strong> Integración en sistemas de seguridad para el control de acceso.</li>
<li><strong>Vehículos Autónomos:</strong> Utilizadas para identificar señales de tráfico, peatones y obstáculos.</li>
<li><strong>Análisis de Video:</strong> Seguimiento de objetos y detección de eventos en videos.</li>
</ul>
<h2 id="5-arquitecturas-pioneras-de-rnc">5. Arquitecturas Pioneras de RNC</h2>
<p>El rápido avance de las RNC se debe a arquitecturas seminales que introdujeron innovaciones cruciales:</p>
<h3 id="lenet-5-1998">LeNet-5 (1998)</h3>
<p>Desarrollada por Yann LeCun, fue una de las primeras RNC exitosas, diseñada para el reconocimiento de dígitos escritos a mano. Sentó las bases para las RNC modernas.</p>
<ul>
<li><strong>Arquitectura:</strong> Consiste en capas convolucionales seguidas de submuestreo (<em>pooling</em>) y capas totalmente conectadas.</li>
<li><strong>Legado:</strong> Demostró que las RNC podían aplicarse con éxito al reconocimiento de patrones visuales, utilizando conceptos como campos receptivos locales y pesos compartidos.</li>
</ul>
<h3 id="alexnet-2012">AlexNet (2012)</h3>
<p>AlexNet ganó el desafío ImageNet ILSVRC en 2012, superando significativamente a su competidor más cercano (tasa de error top-5 de 15.3% frente a 26.2%). Popularizó las RNC en la visión por computadora.</p>
<ul>
<li><strong>Innovaciones Clave:</strong> Fue la primera arquitectura importante en utilizar la activación <strong>ReLU</strong>, lo que aceleró el entrenamiento 6 veces al evitar la saturación de activación. También utilizó <em>Dropout</em> para prevenir el sobreajuste.</li>
<li><strong>Estructura:</strong> Incluye 5 capas convolucionales (con <em>Max-Pooling</em> superpuesto después de la 1ª, 2ª y 5ª) seguidas de 2 capas totalmente conectadas y termina con una capa Softmax.</li>
<li><strong>Desventajas:</strong> Es un modelo grande, con alrededor de 60 millones de parámetros.</li>
</ul>
<h3 id="vggnet-2014">VGGNet (2014)</h3>
<p>VGGNet fue subcampeona en ILSVRC 2014. Su principal contribución fue demostrar que la <strong>profundidad</strong> de la red es fundamental para un buen rendimiento.</p>
<ul>
<li><strong>Principio de Diseño:</strong> Utiliza una arquitectura extremadamente homogénea, basada en el apilamiento de <strong>filtros convolucionales pequeños de $3 \times 3$</strong> con <em>stride</em> 1 y <em>padding</em> 1, seguidos de <em>Max Pooling</em> de $2 \times 2$ con <em>stride</em> 2.</li>
<li><strong>Variantes:</strong> VGG-16 y VGG-19 (con 16 y 19 capas de peso, respectivamente).</li>
<li><strong>Costo:</strong> A pesar de su eficacia, VGGNet es costosa de evaluar y usa mucha memoria y parámetros (hasta 140M).</li>
</ul>
<h3 id="googlenet--inception-v1-2014">GoogLeNet / Inception V1 (2014)</h3>
<p>GoogLeNet ganó el ILSVRC 2014. Se distingue por reducir drásticamente el número de parámetros (4M, frente a los 60M de AlexNet).</p>
<ul>
<li><strong>Módulo Inception:</strong> El núcleo arquitectónico. Este módulo procesa la entrada en <strong>paralelo</strong> utilizando convoluciones $1\times 1$, $3\times 3$, $5\times 5$, y <em>Max Pooling</em> $3\times 3$, concatenando sus salidas. Esto permite a la red capturar características a múltiples escalas.</li>
<li><strong>Reducción de Dimensionalidad $1\times 1$:</strong> Las convoluciones $1\times 1$ se utilizan principalmente para reducir la dimensionalidad y el costo computacional, permitiendo arquitecturas más profundas y eficientes.</li>
<li><strong><em>Global Average Pooling</em> (GAP):</strong> Reemplaza las capas FC tradicionales al final, lo que elimina una gran cantidad de parámetros y reduce el sobreajuste.</li>
<li><strong>Clasificadores Auxiliares:</strong> Ramas intermedias que ayudan a regularizar la red y abordar el problema del gradiente desvanecedor durante el entrenamiento.</li>
</ul>
<h3 id="residual-networks-resnet-2015">Residual Networks (ResNet) (2015)</h3>
<p>ResNet ganó el ILSVRC 2015. Esta arquitectura fue desarrollada para resolver el problema de la degradación y el gradiente desvanecedor cuando se aumenta el número de capas en una red.</p>
<ul>
<li><strong>Conexiones de Salto (<em>Skip Connections</em>):</strong> La innovación principal. Estas conexiones de atajo conectan las activaciones de una capa a capas posteriores, omitiendo algunas capas intermedias y formando un <strong>Bloque Residual</strong>.</li>
<li><strong>Aprendizaje Residual:</strong> En lugar de aprender un mapeo directo $H(x)$, la red aprende el mapeo residual $F(x) = H(x) - x$. Esto facilita el entrenamiento de redes extremadamente profundas (por ejemplo, ResNet-152, que es 8 veces más profunda que VGG-19, pero con menos parámetros).</li>
<li><strong>Rendimiento:</strong> Un conjunto de ResNets logró una tasa de error top-5 de solo <strong>3.57%</strong> en el conjunto de prueba de ImageNet.</li>
</ul>
<h2 id="6-marcos-de-trabajo-frameworks-de-deep-learning">6. Marcos de Trabajo (<em>Frameworks</em>) de Deep Learning</h2>
<p>El crecimiento de las RNC se ha visto impulsado por potentes marcos de trabajo que facilitan su entrenamiento e implementación. Los más destacados son:</p>
<table>
  <thead>
      <tr>
          <th style="text-align: left">Framework</th>
          <th style="text-align: left">Desarrollador</th>
          <th style="text-align: left">Año de Lanzamiento</th>
          <th style="text-align: left">Nivel API</th>
          <th style="text-align: left">Características Destacadas</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td style="text-align: left"><strong>TensorFlow</strong></td>
          <td style="text-align: left">Google</td>
          <td style="text-align: left">2015</td>
          <td style="text-align: left">Alto y Bajo</td>
          <td style="text-align: left">Marco de código abierto, ofrece herramientas para desarrollo y despliegue. Rápido, alto rendimiento.</td>
      </tr>
      <tr>
          <td style="text-align: left"><strong>Keras</strong></td>
          <td style="text-align: left">—</td>
          <td style="text-align: left">—</td>
          <td style="text-align: left">Alto</td>
          <td style="text-align: left">Marco de alto nivel en Python, se utiliza a menudo dentro de TensorFlow, permite experimentación rápida. Es el más popular.</td>
      </tr>
      <tr>
          <td style="text-align: left"><strong>PyTorch</strong></td>
          <td style="text-align: left">Facebook AI Research</td>
          <td style="text-align: left">2017</td>
          <td style="text-align: left">Bajo</td>
          <td style="text-align: left">Notado por su grafo computacional dinámico y eficiencia de memoria. Buenas capacidades de depuración (<em>debugging</em>).</td>
      </tr>
  </tbody>
</table>
<p>La elección del framework depende de las características más importantes para el caso de uso dado. Por ejemplo, PyTorch es más flexible debido a su bajo nivel de API, mientras que Keras es más conciso y legible, aunque más lento.</p>
<p><a href="https://unsplash.com/es/fotos/textil-floral-azul-y-blanco-11KDtiUWRq4">Background image</a> by  <strong>Uriel SC</strong> on Unsplash.</p>

  

<section id="subscriptionSection" class="section narrow">
    <div class="subscription-container">
        <div class="subscription-content">
            <h3 class="subscription-heading">
                Únase a nuestra lista de correo electrónico y reciba notificaciones sobre nuevos contenidos.
            </h3>
            <p class="subscription-text">
                Sé el primero en recibir nuestro contenido.
                Prometemos no enviar spam a su bandeja de entrada ni compartir su correo electrónico con terceros.
            </p>
            <form id="subscriptionForm" class="subscription-form" action="https://formspree.io/mdowgwww" method="POST">
                <input
                  id="emailInput"
                  class="subscription-input"
                  placeholder="your@email.com"
                  name="email"
                  type="email"
                  required
                  pattern="^[a-zA-Z0-9.!#$%&'*+/=?^_`{|}~-]+@[a-zA-Z0-9](?:[a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?(?:\.[a-zA-Z0-9](?:[a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?)*$"
                />
                <button id="submitButton"
                  class="submit-button"
                  type="submit"
                >
                    Unirse
                </button>
                <div class="subscription-error-message">
                    El correo electrónico que ingresó no es válido.
                </div>
            </form>
        </div>
    </div>
</section>


<script src="//localhost:1313/js/addFormStyles.js"></script>



    </article>


    





    
    
    
        
    




<section id="articleNext" class="section nartrow">
    <h3 class="footer-next-heading">More articles from angelortizv </h3>
    <div class="footer-spacer"></div>
    <div class="next-articles-grid" numberOfArticles={numberOfArticles}>
        <div class="post-row">
            
                <a href="//localhost:1313/blog/el-arte-del-c%C3%B3digo-limpio-una-gu%C3%ADa-para-escribir-software-que-perdure/" class="article-link"
                 id="article-link-bigger">
                    <div>
                        <div class="image-container">
                            <img src="//localhost:1313/uploads/content/2025/2025-clean-code.png" class="article-image" />
                        </div>
                        <div>
                            <h2 class="article-title">
                                El Arte del Código Limpio: Una Guía para Escribir Software que Perdure
                            </h2>
                            <p class="article-excerpt">
                                ¿Alguna vez has abierto un archivo de código y has pensado &#39;WTF&#39;?. Si eres programador, es casi seguro que sí. Has tenido que navegar por una maraña de código mal escrito, perdiendo horas y recursos valiosos en el proceso. El código incorrecto no solo ralentiza el desarrollo y disminuye la productividad, sino que puede llevar al fracaso de una empresa.
                            </p>
                            <div class="article-metadata">
                                October 10, 2025 · 16 min read
                            </div>
                        </div>
                    </div>
                </a>
            
                <a href="//localhost:1313/blog/rlhf-101-qu%C3%A9-es-y-por-qu%C3%A9-importa-el-aprendizaje-por-refuerzo-con-retroalimentaci%C3%B3n-humana/" class="article-link"
                >
                    <div>
                        <div class="image-container">
                            <img src="//localhost:1313/uploads/content/2025/2025-RLHF101.png" class="article-image" />
                        </div>
                        <div>
                            <h2 class="article-title">
                                RLHF 101: ¿Qué es y por qué importa el Aprendizaje por Refuerzo con Retroalimentación Humana?
                            </h2>
                            <p class="article-excerpt">
                                En los últimos años, los modelos de inteligencia artificial han dado saltos extraordinarios. Pero detrás de su comportamiento cada vez más natural, coherente y útil, hay un ingrediente poco conocido pero fundamental: el Aprendizaje por Refuerzo con Retroalimentación Humana, conocido como RLHF (por sus siglas en inglés: Reinforcement Learning with Human Feedback). 
                            </p>
                            <div class="article-metadata">
                                July 7, 2025 · 4 min read
                            </div>
                        </div>
                    </div>
                </a>
            
        </div>
    </div>
</section>

</section>


 <script src="//localhost:1313/js/progressBar.js"></script>

        
        <div class="footer-gradient"></div>
    <div class="section narrow">
      <div class="footer-hr"></div>
      <div class="footer-container">
        <div class="footer-text">
          © 2025 <a href="//localhost:1313/"> angelortizv </a>
        </div>
        <div class="social-icon-outer">
    <div class="social-icon-container">
        
            
                
                <a href="https://github.com/angelortizv"><svg
class="social-icon-image"
width="14"
height="14"
viewBox="0 0 14 14"
fill="none"
xmlns="http://www.w3.org/2000/svg"
>
<path
  fillRule="evenodd"
  clipRule="evenodd"
  d="M7 0C3.1325 0 0 3.21173 0 7.17706C0 10.3529 2.00375 13.0353 4.78625 13.9863C5.13625 14.0491 5.2675 13.8338 5.2675 13.6454C5.2675 13.4749 5.25875 12.9097 5.25875 12.3087C3.5 12.6406 3.045 11.8691 2.905 11.4653C2.82625 11.259 2.485 10.622 2.1875 10.4516C1.9425 10.317 1.5925 9.98508 2.17875 9.97611C2.73 9.96714 3.12375 10.4964 3.255 10.7118C3.885 11.7973 4.89125 11.4923 5.29375 11.3039C5.355 10.8374 5.53875 10.5234 5.74 10.3439C4.1825 10.1645 2.555 9.54549 2.555 6.80026C2.555 6.01976 2.82625 5.37382 3.2725 4.87143C3.2025 4.692 2.9575 3.95635 3.3425 2.96951C3.3425 2.96951 3.92875 2.78111 5.2675 3.70516C5.8275 3.54367 6.4225 3.46293 7.0175 3.46293C7.6125 3.46293 8.2075 3.54367 8.7675 3.70516C10.1063 2.77214 10.6925 2.96951 10.6925 2.96951C11.0775 3.95635 10.8325 4.692 10.7625 4.87143C11.2087 5.37382 11.48 6.01079 11.48 6.80026C11.48 9.55446 9.84375 10.1645 8.28625 10.3439C8.54 10.5682 8.75875 10.9988 8.75875 11.6717C8.75875 12.6316 8.75 13.4032 8.75 13.6454C8.75 13.8338 8.88125 14.0581 9.23125 13.9863C11.9963 13.0353 14 10.3439 14 7.17706C14 3.21173 10.8675 0 7 0Z"
  fill="#73737D"
/>
</svg></a>
                <span class="hidden">https://github.com/angelortizv</span>
            
        
            
                
                <a href="https://instagram.com/angelortizv"><svg
class="social-icon-image"
width="13"
height="13"
viewBox="0 0 13 13"
fill="none"
xmlns="http://www.w3.org/2000/svg"
>
<path
  fillRule="evenodd"
  clipRule="evenodd"
  d="M-3.05176e-05 3.97163C-3.05176e-05 1.77803 1.77824 -0.000244141 3.97184 -0.000244141H9.0281C11.2217 -0.000244141 13 1.77802 13 3.97163V9.02788C13 11.2215 11.2217 12.9998 9.0281 12.9998H3.97184C1.77824 12.9998 -3.05176e-05 11.2215 -3.05176e-05 9.02789V3.97163ZM3.97184 1.281C2.48585 1.281 1.28122 2.48564 1.28122 3.97163V9.02789C1.28122 10.5139 2.48585 11.7185 3.97184 11.7185H9.0281C10.5141 11.7185 11.7187 10.5139 11.7187 9.02788V3.97163C11.7187 2.48564 10.5141 1.281 9.0281 1.281H3.97184Z"
  fill="#73737D"
/>
<path
  fillRule="evenodd"
  clipRule="evenodd"
  d="M3.07483 6.55115C3.07483 4.64454 4.61242 3.09253 6.51702 3.09253C8.42162 3.09253 9.95921 4.64454 9.95921 6.55115C9.95921 8.45776 8.42162 10.0098 6.51702 10.0098C4.61242 10.0098 3.07483 8.45776 3.07483 6.55115ZM6.51702 4.37378C5.32709 4.37378 4.35608 5.34508 4.35608 6.55115C4.35608 7.75722 5.32709 8.72853 6.51702 8.72853C7.70695 8.72853 8.67796 7.75722 8.67796 6.55115C8.67796 5.34508 7.70695 4.37378 6.51702 4.37378Z"
  fill="#73737D"
/>
<path
  fillRule="evenodd"
  clipRule="evenodd"
  d="M9.95062 3.87075C10.4035 3.87075 10.7706 3.50149 10.7706 3.04597C10.7706 2.59046 10.4035 2.22119 9.95062 2.22119C9.49776 2.22119 9.13065 2.59046 9.13065 3.04597C9.13065 3.50149 9.49776 3.87075 9.95062 3.87075Z"
  fill="#73737D"
/>
</svg></a>
                <span class="hidden">https://instagram.com/angelortizv</span>
            
        
            
                
                <a href="http://linkedin.com/in/angelortizv/"><svg
class="social-icon-image"
width="14"
height="14"
viewBox="0 0 14 14"
fill="none"
xmlns="http://www.w3.org/2000/svg"
{...props}
>
<path
  fillRule="evenodd"
  clipRule="evenodd"
  d="M3.59615 13.125H0.871552V4.36523H3.59615V13.125ZM2.24847 3.16406C1.81878 3.16406 1.44769 3.00781 1.13519 2.69531C0.822692 2.38281 0.666443 2.01171 0.666443 1.58203C0.666443 1.15234 0.822692 0.781248 1.13519 0.468749C1.44769 0.156249 1.81878 0 2.24847 0C2.67816 0 3.04925 0.156249 3.36175 0.468749C3.67425 0.781248 3.8305 1.15234 3.8305 1.58203C3.8305 2.01171 3.67425 2.38281 3.36175 2.69531C3.04925 3.00781 2.67816 3.16406 2.24847 3.16406ZM13.7915 13.125H11.0669V8.84765C11.0669 8.14452 11.0083 7.63671 10.8911 7.32421C10.6763 6.79687 10.2563 6.5332 9.63134 6.5332C9.00634 6.5332 8.56689 6.76757 8.31298 7.23632C8.11767 7.58788 8.02001 8.10546 8.02001 8.78905V13.125H5.32471V4.36523H7.93212V5.5664H7.96142C8.15673 5.17578 8.46923 4.85351 8.89892 4.59961C9.36767 4.28711 9.91454 4.13086 10.5395 4.13086C11.8091 4.13086 12.6977 4.53125 13.2055 5.33203C13.5962 5.97656 13.7915 6.97265 13.7915 8.3203V13.125Z"
  fill="#73737D"
/>
</svg></a>
                <span class="hidden">http://linkedin.com/in/angelortizv/</span>
            
        
    </div>
</div>
    </div>
</div>

    </div>

    
    <script src="//localhost:1313/js/prism.js"></script>
</body>

</html>